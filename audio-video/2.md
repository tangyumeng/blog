## iOS 直播推流


就直播推流来说，目前的技术已经比较成熟，选择 [LFLiveKit](https://github.com/LaiFengiOS/LFLiveKit) 来进行学习、分析

LFLiveKit 已经提供了比较全面的功能， 包括  
1. 录制  
2. 录制过程中美颜（GPUImage）  
3. 支持 H.264 + AAC 进行硬编  
4. 较差网络丢帧策略  
5. RTMP 协议传输数据  


下载代码后，作者提供的 samples 目录下 LFLiveKitDemo 可以查看运行效果： 

其中可以在 SecondViewController 中 看到是用 LFLivePreview 实现的 UI，需要在 startLiveButton 中配置 LFLiveStreamInfo url 为上一节 server 配置的 url， 例如 `rtmp://192.168.1.2:1935/rtmplive/room` , 
其中 room 内容可以自己提供，生产环境中，可以根据业务需求是用主播的直播间ID + 一些内容来实现。


在  LFLivePreview 中，除了 UI 实现代码， 以及音频、视频 授权代码外，关键的业务代码都是在 LFLiveSession 类中实现。



1. 初始化 LFLivePreview 对象，请求 音、视频授权，授权成功后，对 LFLiveSession 对象设置 running 操作，其中 `- (void)setRunning:(BOOL)running` 方法会进行视频采集对象(LFVideoCapture)、音频采集对象(LFAudioCapture)的初始化

2. 初始化 session 对象.初始化过程中选择配置 音、视频 采集参数 ， 比特率、采样率等
	
2. 然后启动 RTMP 通道

	<pre><code>- (void)startLive:(LFLiveStreamInfo *)streamInfo {
	    if (!streamInfo) return;
	    _streamInfo = streamInfo;
	    _streamInfo.videoConfiguration = _videoConfiguration;
	    _streamInfo.audioConfiguration = _audioConfiguration;
	    [self.socket start];
	}
	- (id<LFStreamSocket>)socket {
	    if (!_socket) {
	        _socket = [[LFStreamRTMPSocket alloc] initWithStream:self.streamInfo
	                                           reconnectInterval:self.reconnectInterval
	                                              reconnectCount:self.reconnectCount];
	        [_socket setDelegate:self];
	    }
	    return _socket;
	}
	</code></pre>

4. LFLiveSession 中 <pre><code>/// 声音采集
@property (nonatomic, strong) LFAudioCapture *audioCaptureSource;
/// 视频采集
@property (nonatomic, strong) LFVideoCapture *videoCaptureSource;
/// 音频编码
@property (nonatomic, strong) id\<LFAudioEncoding\> audioEncoder;
/// 视频编码
@property (nonatomic, strong) id\<LFVideoEncoding\> videoEncoder;</code></pre>

	这四个变量处理音、视频采集， 音、视频编码的事情。
	其中音视频采集可以关注 `LFAudioCaptureDelegate`, `LFVideoCaptureDelegate` 这两个回调，两个回调中，根据当前的 RTMP 连接状态，输入对应的音、视频编码器中进行处理。 例如音频采集回调中： 
	<pre><code>- (void)captureOutput:(nullable LFAudioCapture *)capture
	            audioData:(nullable NSData*)audioData {
	    if (self.uploading) [self.audioEncoder
	                         encodeAudioData:audioData timeStamp:NOW];
	}</code></pre>

5. 上传数据到编码器中处理，处理完成后，在编码器的回调中把数据通过RTMP 上传到推流服务器:
<pre><code>//LFLiveSession
- (void)audioEncoder:(nullable id\<LFAudioEncoding\>)encoder
          audioFrame:(nullable LFAudioFrame *)frame {
	    if (self.uploading){
	        self.hasCaptureAudio = YES;
	        if(self.AVAlignment) [self pushSendBuffer:frame];
	    }
}
- (void)pushSendBuffer:(LFFrame*)frame{
	    if(self.relativeTimestamps == 0){
	        self.relativeTimestamps = frame.timestamp;
	    }
	    frame.timestamp = [self uploadTimestamp:frame.timestamp];
	    [self.socket sendFrame:frame];
}<br></code></pre>


上述是 LFLiveKit 基本流程。后面就每个知识点详细展开记录一下。